 C1 \
1.2 基本术语
* 样本：也称为“示例”，是关于一个事件或对象的描述。任何事物都可以由若干“特征”（或称为“属性”）唯一刻画出来，而向量的各个维度即可用来描述各个特征。向量中的元素用分号“;”分隔时表示此向量为列向量，用逗号“,”分隔时表示为行向量。
* 样本空间：也称为“输入空间”或“属性空间”。表示样本的特征向量所在的空间为样本空间，通常用花式大写的 &chi; 表示。
* 数据集：数据集通常用集合来表示, 一般同一份数据集中的每个样本都含有相同个数的特征。
* 模型：机器学习的一般流程如下：首先收集若干样本（假设此时有 100 个），然后将其分为训练样本（80 个）和测试样本（20 个），其中 80 个训练样本构成的集合称为“训练集”，20 个测试样本构成的集合称为“测试集”，接着选用某个机器学习算法，让其在训练集上进行“学习”（或称为“训练”），然后产出得到“模型”（或称为“学习器”），最后用测试集来测试模型的效果。
* 标记：上文提到机器学习的本质就是在学习样本在某个方面的表现是否存在潜在的规律，我们称该方面的信息为“标记”。根据标记的取值类型不同，可将机器学习任务分为以下两类：
    - 当标记取值为离散型时，称此类任务为“分类”
    - 当标记取值为连续型时，称此类任务为“回归”
* 根据是否有用到标记信息，可将机器学习任务分为以下两类：
    - 在模型训练阶段有用到标记信息时，称此类任务为“监督学习”
    - 在模型训练阶段没用到标记信息时，称此类任务为“无监督学习”
* 泛化：由于机器学习的目标是根据已知来对未知做出尽可能准确的判断，因此对未知事物判断的准确与否才是衡量一个模型好坏的关键，我们称此为“泛化”能力。
* 分布：此处的“分布”指的是概率论中的概率分布，通常假设样本空间服从一个未知“分布” $D$ ，而我们收集到的每个样本都是独立地从该分布中采样得到，即“独立同分布”。通常收集到的样本越多，越能从样本中反推出 $D$ 的信息，即越接近真相。\
1.3 假设空间
* 以数据作为训练集可以有多个假设空间，且在不同的假设空间中都有可能学得能够拟合训练集的模型，我们将所有能够拟合训练集的模型构成的集合称为“版本空间”。\
1.4 归纳偏好
* 当选用一元线性回归算法时，学得的模型是一元一次函数，当选用多项式回归算法时，学得的模型是一元二次函数，所以不同的机器学习算法有不同的偏好，我们称为“归纳偏好”。“奥卡姆剃刀”原则认为“若有多个假设与观察一致，则选最简单的那个”。\
C2 \
2.1 经验误差与过拟合
* 错误率：$E=\frac{a}{m}$ 其中 $m$ 为样本个数，$a$ 为分类错误样本个数。
* 精度：精度 =1-错误率。
* 误差：学习器的实际预测输出与样本的真实输出之间的差异。
* 经验误差：学习器在训练集上的误差，又称为“训练误差”。
* 泛化误差：学习器在新样本上的误差。\
在分类问题中也会使用误差的概念，此时的“差异”指的是学习器的实际预测输出的类别与样本真实的类别是否一致，若一致则“差异”为 0，若不一致则“差异”为 1，训练误差是在训练集上差异的平均值，而泛化误差则是在新样本（训练集中未出现过的样本）上差异的平均值。
* 过拟合:是由于模型的学习能力相对于数据来说过于强大，反过来说，欠拟合是因为模型的学习能力相对于数据来说过于低下。
2.2 评估方法 \
本节介绍了 3 种模型评估方法：留出法、交叉验证法、自助法。留出法由于操作简单，因此最常用；交叉验证法常用于对比同一算法的不同参数配置之间的效果，以及对比不同算法之间的效果；自助法常用于集成学习 \
2.2.1 算法参数（超参数）与模型参数 \
算法参数是指算法本身的一些参数（也称超参数），例如 $k$ 近邻的近邻个数 $k$、支持向量机的参数 $C$（详见“西瓜书”第 6 章式 (6.29)）。算法配置好相应参数后进行训练，训练结束会得到一个模型，例如支持向量机最终会得到 $w$ 和 $b$ 的具体数值（此处不考虑核函数），这就是模型参数，模型配置好相应模型参数后即可对新样本做预测。\
2.2.2 验证集 \
交叉验证法操作起来较为复杂，实际中更多采用的是：先用留出法将数据集划分出训练集和测试集，然后再对训练集采用留出法划分出训练集和新的测试集，称新的测试集为验证集，接着基于验证集的测试结果来调参选出最优参数配置方案，最后将验证集合并进训练集（训练集数据量够的话也可不合并），用选出的最优参数配置在合并后的训练集上重新训练，再用测试集来评估训练得到的模型的性能。\
2.3 性能度量 \
本节性能度量指标较多，但是一般常用的只有错误率、精度、查准率、查全率、F1、ROC 和 AUC。 \
2.3.2 \
查准率 P：被学习器预测为正例的样例中有多大比例是真正例。 \
查全率 R：所有正例当中有多大比例被学习器预测为正例。 \
2.3.3 \
P-R 曲线的画法与 ROC 曲线的画法类似，也是通过依次改变模型阈值，然后计算出查准率和查全
率并画出相应坐标点 \
2.3.5 &beta; 通过加权影响查全率和查准率 \
2.3.6 macro-*P* 和 macro-*R* \
通过 *TP*、*FP*、*TN*、*FN*计算得到的综合指标 \
2.3.7  \
* 真正例率 TPR。先解释公式中出现的真正例和假反例，真正例即实际为正例预测结果也为正例，假反例即实际为正例但预测结果为反例 \
* 假正例率 FPR。先解释式子中出现的假正例和真反例，假正例即实际为反例但预测结果为正例，真反例即实际为反例预测结果也为反例。 \
2.3.8 ROC曲线的绘制 \
ROC 曲线上每一个点都表示学习器 f(s) 在特定阈值下构成的一个二分类器，越好的二分类器其假正例率（反例被预测错误的概率，横轴）越小，真正例率（正例被预测正确的概率，纵轴）越大，所以这个点越靠左上角（即点 (0, 1)）越好。因此，越好的学习器，其ROC 曲线上的点越靠左上角，相应的 ROC 曲线下的面积也越大，即 AUC 也越大。
2.4 比较检验 \
从统计学的角度，取得的性能度量的值本质上仍是一个随机变量，因此并不能简单用比较大小来直接判定算法（或者模型）之间的优劣，而需要更置信的方法来进行判定。 \
2.5 偏差与方差 \
:v:




